{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - PHY 256\n",
    "\n",
    "### Serena Flint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Data from .CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 61579\n",
      "\n",
      "Array Formatting:\n",
      "['GalaxyID', 'Class1.1', 'Class1.2', 'Class1.3', 'Class2.1', 'Class2.2', 'Class3.1', 'Class3.2', 'Class4.1', 'Class4.2', 'Class5.1', 'Class5.2', 'Class5.3', 'Class5.4', 'Class6.1', 'Class6.2', 'Class7.1', 'Class7.2', 'Class7.3', 'Class8.1', 'Class8.2', 'Class8.3', 'Class8.4', 'Class8.5', 'Class8.6', 'Class8.7', 'Class9.1', 'Class9.2', 'Class9.3', 'Class10.1', 'Class10.2', 'Class10.3', 'Class11.1', 'Class11.2', 'Class11.3', 'Class11.4', 'Class11.5', 'Class11.6']\n"
     ]
    }
   ],
   "source": [
    "#CSV file name to be read in\n",
    "file = \"TrainData.csv\"\n",
    "\n",
    "fields = []\n",
    "rows = []\n",
    "\n",
    "#adds file data to rows[]\n",
    "with open(file, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)  \n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "        \n",
    "    #this is the limiting number of training cases from known galaxy classifications\n",
    "    print(\"Total number of rows:\", csvreader.line_num)\n",
    "\n",
    "print(\"\\nArray Formatting:\")\n",
    "print(rows[0])\n",
    "\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Elliptical: 2200\n",
      "Number Spiral A: 517\n",
      "Number Spiral B: 2283\n",
      "\n",
      "Total Training Size: 5000\n"
     ]
    }
   ],
   "source": [
    "#possible bins\n",
    "bin1A = [] #elliptical\n",
    "bin1B = [] #spiral\n",
    "bin2A = [] #bar/no bar\n",
    "bin2B = [] #bar/no bar\n",
    "\n",
    "for i in range (1, 5001):\n",
    "    if rows[i][1] > rows[i][2]:\n",
    "        bin1A.append(rows[i][0])\n",
    "    else:\n",
    "        if rows[i][4] > rows[i][5]:\n",
    "            bin2A.append(rows[i][0])\n",
    "        else:\n",
    "            bin2B.append(rows[i][0])\n",
    "\n",
    "print(\"Number Elliptical:\", len(bin1A))\n",
    "print(\"Number Spiral A:\", len(bin2A))\n",
    "print(\"Number Spiral B:\", len(bin2B))\n",
    "\n",
    "print(\"\\nTotal Training Size:\", (len(bin1A)+len(bin2A)+len(bin2B)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Moving Files to Correct Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File(s) Not Found\n",
      "Images likely already transferred!\n"
     ]
    }
   ],
   "source": [
    "#new path headers\n",
    "path1A = \"bin1A/\"\n",
    "path2A = \"bin2A/\"\n",
    "path2B = \"bin2B/\"\n",
    "\n",
    "#moving files from the dataset into their proper bins\n",
    "try:\n",
    "    for i in range(0,len(bin1A)):\n",
    "        file1A = bin1A[i]+\".jpg\"\n",
    "        os.rename(\"dataset/photos/\"+file1A, path1A+file1A)\n",
    "\n",
    "    for i in range(0,len(bin2A)):\n",
    "        file2A = bin2A[i]+\".jpg\"\n",
    "        os.rename(\"dataset/photos/\"+file2A, path2A+file2A)\n",
    "\n",
    "    for i in range(0,len(bin2B)):\n",
    "        file2B = bin2B[i]+\".jpg\"\n",
    "        os.rename(\"dataset/photos/\"+file2B, path2B+file2B)\n",
    "except FileNotFoundError:\n",
    "        print(\"File(s) Not Found\")\n",
    "        print(\"Images likely already transferred!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#machine learning libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#plotting and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = []\n",
    "\n",
    "#loading 1A images into an array\n",
    "#target_size resizes images\n",
    "for i in range (0, len(bin1A)):\n",
    "    img = image.load_img(\"bin1A/\" + bin1A[i] + \".jpg\", target_size=(224,224,3), grayscale = False)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    training_images.append(img)\n",
    "    \n",
    "#loading 2A images into an array\n",
    "for i in range (0, len(bin2A)):\n",
    "    img = image.load_img(\"bin2A/\" + bin2A[i] + \".jpg\", target_size=(224,224,3), grayscale = False)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    training_images.append(img)\n",
    "\n",
    "#loading 2B images into an array\n",
    "for i in range (0, len(bin2B)):\n",
    "    img = image.load_img(\"bin2B/\" + bin2B[i] + \".jpg\", target_size=(224,224,3), grayscale = False)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    training_images.append(img)\n",
    "    \n",
    "X = np.array(training_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Label Array & Validation Set\n",
    "\n",
    "Since the dataset with galaxy images has a more complicated solution set, I'm manually creating a solution set suited more to our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels: 5000\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for i in range (0,len(bin1A)):\n",
    "    labels.append(\"1\") #1A\n",
    "\n",
    "for j in range (0, len(bin2A)):\n",
    "    labels.append(\"2\") #2A\n",
    "    \n",
    "for k in range (0, len(bin2B)):\n",
    "    labels.append(\"2\") #2B\n",
    "    \n",
    "y = to_categorical(labels)\n",
    "print(\"Total Labels:\", len(labels)) #Sanity Check\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(224,224,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seren\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "4000/4000 [==============================] - ETA: 50:55 - loss: 1.0854 - acc: 0.50 - ETA: 40:44 - loss: 1.5344 - acc: 0.45 - ETA: 32:22 - loss: 1.7467 - acc: 0.46 - ETA: 28:21 - loss: 1.5005 - acc: 0.52 - ETA: 25:39 - loss: 1.5904 - acc: 0.49 - ETA: 23:48 - loss: 1.6313 - acc: 0.48 - ETA: 22:30 - loss: 1.5313 - acc: 0.49 - ETA: 21:32 - loss: 1.4249 - acc: 0.50 - ETA: 20:41 - loss: 1.3693 - acc: 0.48 - ETA: 19:57 - loss: 1.3213 - acc: 0.48 - ETA: 19:21 - loss: 1.2737 - acc: 0.49 - ETA: 18:50 - loss: 1.2382 - acc: 0.50 - ETA: 18:20 - loss: 1.2081 - acc: 0.50 - ETA: 17:53 - loss: 1.1774 - acc: 0.50 - ETA: 17:29 - loss: 1.1554 - acc: 0.50 - ETA: 17:07 - loss: 1.1275 - acc: 0.51 - ETA: 16:45 - loss: 1.1017 - acc: 0.51 - ETA: 16:28 - loss: 1.0787 - acc: 0.52 - ETA: 16:09 - loss: 1.0570 - acc: 0.52 - ETA: 15:52 - loss: 1.0383 - acc: 0.52 - ETA: 15:35 - loss: 1.0202 - acc: 0.53 - ETA: 15:19 - loss: 1.0088 - acc: 0.52 - ETA: 15:04 - loss: 0.9938 - acc: 0.53 - ETA: 14:49 - loss: 0.9813 - acc: 0.53 - ETA: 14:35 - loss: 0.9695 - acc: 0.54 - ETA: 14:21 - loss: 0.9615 - acc: 0.54 - ETA: 14:09 - loss: 0.9549 - acc: 0.54 - ETA: 13:56 - loss: 0.9480 - acc: 0.53 - ETA: 13:44 - loss: 0.9374 - acc: 0.53 - ETA: 13:32 - loss: 0.9308 - acc: 0.54 - ETA: 13:20 - loss: 0.9231 - acc: 0.54 - ETA: 13:08 - loss: 0.9158 - acc: 0.54 - ETA: 12:57 - loss: 0.9111 - acc: 0.54 - ETA: 12:47 - loss: 0.9033 - acc: 0.54 - ETA: 12:36 - loss: 0.8982 - acc: 0.55 - ETA: 12:25 - loss: 0.8913 - acc: 0.55 - ETA: 12:15 - loss: 0.8839 - acc: 0.55 - ETA: 12:04 - loss: 0.8774 - acc: 0.56 - ETA: 11:53 - loss: 0.8730 - acc: 0.56 - ETA: 11:43 - loss: 0.8677 - acc: 0.56 - ETA: 11:33 - loss: 0.8687 - acc: 0.56 - ETA: 11:23 - loss: 0.8636 - acc: 0.56 - ETA: 11:14 - loss: 0.8585 - acc: 0.56 - ETA: 11:04 - loss: 0.8523 - acc: 0.57 - ETA: 10:54 - loss: 0.8492 - acc: 0.57 - ETA: 10:44 - loss: 0.8470 - acc: 0.57 - ETA: 10:35 - loss: 0.8419 - acc: 0.57 - ETA: 10:25 - loss: 0.8382 - acc: 0.57 - ETA: 10:16 - loss: 0.8365 - acc: 0.57 - ETA: 10:06 - loss: 0.8340 - acc: 0.57 - ETA: 9:57 - loss: 0.8291 - acc: 0.5760 - ETA: 9:48 - loss: 0.8257 - acc: 0.575 - ETA: 9:39 - loss: 0.8236 - acc: 0.577 - ETA: 9:30 - loss: 0.8202 - acc: 0.578 - ETA: 9:21 - loss: 0.8154 - acc: 0.583 - ETA: 9:11 - loss: 0.8107 - acc: 0.586 - ETA: 9:02 - loss: 0.8075 - acc: 0.586 - ETA: 8:52 - loss: 0.8046 - acc: 0.587 - ETA: 8:43 - loss: 0.8010 - acc: 0.589 - ETA: 8:34 - loss: 0.8024 - acc: 0.588 - ETA: 8:25 - loss: 0.7991 - acc: 0.589 - ETA: 8:16 - loss: 0.7968 - acc: 0.591 - ETA: 8:07 - loss: 0.7941 - acc: 0.592 - ETA: 7:58 - loss: 0.7928 - acc: 0.591 - ETA: 7:49 - loss: 0.7904 - acc: 0.591 - ETA: 7:41 - loss: 0.7876 - acc: 0.592 - ETA: 7:33 - loss: 0.7854 - acc: 0.593 - ETA: 7:25 - loss: 0.7822 - acc: 0.594 - ETA: 7:17 - loss: 0.7817 - acc: 0.593 - ETA: 7:09 - loss: 0.7819 - acc: 0.592 - ETA: 7:00 - loss: 0.7811 - acc: 0.592 - ETA: 6:52 - loss: 0.7777 - acc: 0.595 - ETA: 6:44 - loss: 0.7764 - acc: 0.597 - ETA: 6:36 - loss: 0.7735 - acc: 0.599 - ETA: 6:30 - loss: 0.7715 - acc: 0.600 - ETA: 6:23 - loss: 0.7694 - acc: 0.602 - ETA: 6:16 - loss: 0.7683 - acc: 0.601 - ETA: 6:10 - loss: 0.7680 - acc: 0.601 - ETA: 6:03 - loss: 0.7655 - acc: 0.603 - ETA: 5:56 - loss: 0.7628 - acc: 0.604 - ETA: 5:50 - loss: 0.7605 - acc: 0.604 - ETA: 5:43 - loss: 0.7577 - acc: 0.606 - ETA: 5:36 - loss: 0.7563 - acc: 0.606 - ETA: 5:29 - loss: 0.7553 - acc: 0.606 - ETA: 5:22 - loss: 0.7536 - acc: 0.606 - ETA: 5:16 - loss: 0.7511 - acc: 0.607 - ETA: 5:09 - loss: 0.7503 - acc: 0.608 - ETA: 5:03 - loss: 0.7481 - acc: 0.610 - ETA: 4:56 - loss: 0.7480 - acc: 0.611 - ETA: 4:49 - loss: 0.7463 - acc: 0.612 - ETA: 4:41 - loss: 0.7461 - acc: 0.613 - ETA: 4:32 - loss: 0.7436 - acc: 0.615 - ETA: 4:23 - loss: 0.7410 - acc: 0.617 - ETA: 4:15 - loss: 0.7422 - acc: 0.615 - ETA: 4:07 - loss: 0.7406 - acc: 0.616 - ETA: 3:58 - loss: 0.7398 - acc: 0.616 - ETA: 3:49 - loss: 0.7386 - acc: 0.617 - ETA: 3:41 - loss: 0.7367 - acc: 0.619 - ETA: 3:33 - loss: 0.7359 - acc: 0.619 - ETA: 3:25 - loss: 0.7358 - acc: 0.620 - ETA: 3:16 - loss: 0.7346 - acc: 0.621 - ETA: 3:08 - loss: 0.7336 - acc: 0.621 - ETA: 2:59 - loss: 0.7327 - acc: 0.622 - ETA: 2:51 - loss: 0.7314 - acc: 0.623 - ETA: 2:42 - loss: 0.7294 - acc: 0.625 - ETA: 2:34 - loss: 0.7280 - acc: 0.626 - ETA: 2:26 - loss: 0.7258 - acc: 0.627 - ETA: 2:17 - loss: 0.7249 - acc: 0.627 - ETA: 2:09 - loss: 0.7246 - acc: 0.627 - ETA: 2:01 - loss: 0.7229 - acc: 0.627 - ETA: 1:53 - loss: 0.7208 - acc: 0.628 - ETA: 1:45 - loss: 0.7200 - acc: 0.629 - ETA: 1:37 - loss: 0.7174 - acc: 0.631 - ETA: 1:29 - loss: 0.7147 - acc: 0.633 - ETA: 1:21 - loss: 0.7144 - acc: 0.633 - ETA: 1:13 - loss: 0.7134 - acc: 0.634 - ETA: 1:04 - loss: 0.7118 - acc: 0.635 - ETA: 56s - loss: 0.7099 - acc: 0.635 - ETA: 48s - loss: 0.7093 - acc: 0.63 - ETA: 40s - loss: 0.7092 - acc: 0.63 - ETA: 32s - loss: 0.7069 - acc: 0.63 - ETA: 24s - loss: 0.7057 - acc: 0.63 - ETA: 16s - loss: 0.7048 - acc: 0.63 - ETA: 8s - loss: 0.7031 - acc: 0.6384 - 1091s 273ms/step - loss: 0.7023 - acc: 0.6388 - val_loss: 0.5640 - val_acc: 0.7130\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 14:31 - loss: 0.5390 - acc: 0.75 - ETA: 14:08 - loss: 0.5321 - acc: 0.76 - ETA: 13:49 - loss: 0.5752 - acc: 0.70 - ETA: 13:36 - loss: 0.5455 - acc: 0.73 - ETA: 13:24 - loss: 0.5744 - acc: 0.68 - ETA: 13:14 - loss: 0.5965 - acc: 0.66 - ETA: 13:07 - loss: 0.5837 - acc: 0.67 - ETA: 12:59 - loss: 0.5781 - acc: 0.69 - ETA: 12:53 - loss: 0.5766 - acc: 0.70 - ETA: 12:45 - loss: 0.5725 - acc: 0.70 - ETA: 12:38 - loss: 0.5715 - acc: 0.71 - ETA: 12:32 - loss: 0.5612 - acc: 0.72 - ETA: 12:24 - loss: 0.5541 - acc: 0.73 - ETA: 12:17 - loss: 0.5568 - acc: 0.72 - ETA: 12:11 - loss: 0.5669 - acc: 0.71 - ETA: 12:04 - loss: 0.5678 - acc: 0.71 - ETA: 11:57 - loss: 0.5699 - acc: 0.71 - ETA: 11:50 - loss: 0.5658 - acc: 0.71 - ETA: 11:43 - loss: 0.5605 - acc: 0.71 - ETA: 11:36 - loss: 0.5651 - acc: 0.71 - ETA: 11:31 - loss: 0.5615 - acc: 0.72 - ETA: 11:25 - loss: 0.5703 - acc: 0.72 - ETA: 11:19 - loss: 0.5702 - acc: 0.72 - ETA: 11:12 - loss: 0.5675 - acc: 0.72 - ETA: 11:05 - loss: 0.5655 - acc: 0.72 - ETA: 10:58 - loss: 0.5639 - acc: 0.72 - ETA: 10:52 - loss: 0.5603 - acc: 0.72 - ETA: 10:45 - loss: 0.5649 - acc: 0.72 - ETA: 10:37 - loss: 0.5621 - acc: 0.72 - ETA: 10:30 - loss: 0.5573 - acc: 0.73 - ETA: 10:24 - loss: 0.5613 - acc: 0.72 - ETA: 10:17 - loss: 0.5608 - acc: 0.73 - ETA: 10:10 - loss: 0.5613 - acc: 0.72 - ETA: 10:03 - loss: 0.5628 - acc: 0.72 - ETA: 9:57 - loss: 0.5669 - acc: 0.7232 - ETA: 9:50 - loss: 0.5619 - acc: 0.726 - ETA: 9:43 - loss: 0.5619 - acc: 0.724 - ETA: 9:37 - loss: 0.5591 - acc: 0.725 - ETA: 9:30 - loss: 0.5577 - acc: 0.726 - ETA: 9:24 - loss: 0.5558 - acc: 0.732 - ETA: 9:17 - loss: 0.5543 - acc: 0.732 - ETA: 9:11 - loss: 0.5516 - acc: 0.735 - ETA: 9:04 - loss: 0.5496 - acc: 0.735 - ETA: 8:58 - loss: 0.5465 - acc: 0.740 - ETA: 8:51 - loss: 0.5474 - acc: 0.736 - ETA: 8:45 - loss: 0.5501 - acc: 0.733 - ETA: 8:38 - loss: 0.5475 - acc: 0.735 - ETA: 8:31 - loss: 0.5502 - acc: 0.732 - ETA: 8:24 - loss: 0.5536 - acc: 0.731 - ETA: 8:17 - loss: 0.5507 - acc: 0.732 - ETA: 8:10 - loss: 0.5528 - acc: 0.732 - ETA: 8:04 - loss: 0.5530 - acc: 0.732 - ETA: 7:57 - loss: 0.5528 - acc: 0.730 - ETA: 7:51 - loss: 0.5530 - acc: 0.729 - ETA: 7:44 - loss: 0.5538 - acc: 0.730 - ETA: 7:37 - loss: 0.5560 - acc: 0.728 - ETA: 7:31 - loss: 0.5563 - acc: 0.727 - ETA: 7:24 - loss: 0.5573 - acc: 0.727 - ETA: 7:17 - loss: 0.5569 - acc: 0.728 - ETA: 7:10 - loss: 0.5560 - acc: 0.729 - ETA: 7:04 - loss: 0.5570 - acc: 0.728 - ETA: 6:57 - loss: 0.5585 - acc: 0.726 - ETA: 6:51 - loss: 0.5581 - acc: 0.727 - ETA: 6:44 - loss: 0.5585 - acc: 0.726 - ETA: 6:37 - loss: 0.5579 - acc: 0.726 - ETA: 6:31 - loss: 0.5581 - acc: 0.726 - ETA: 6:24 - loss: 0.5581 - acc: 0.725 - ETA: 6:17 - loss: 0.5589 - acc: 0.724 - ETA: 6:11 - loss: 0.5576 - acc: 0.725 - ETA: 6:04 - loss: 0.5583 - acc: 0.723 - ETA: 5:58 - loss: 0.5601 - acc: 0.722 - ETA: 5:52 - loss: 0.5610 - acc: 0.722 - ETA: 5:46 - loss: 0.5600 - acc: 0.723 - ETA: 5:40 - loss: 0.5604 - acc: 0.722 - ETA: 5:33 - loss: 0.5604 - acc: 0.722 - ETA: 5:27 - loss: 0.5598 - acc: 0.722 - ETA: 5:20 - loss: 0.5605 - acc: 0.722 - ETA: 5:14 - loss: 0.5593 - acc: 0.724 - ETA: 5:07 - loss: 0.5614 - acc: 0.723 - ETA: 5:01 - loss: 0.5603 - acc: 0.723 - ETA: 4:55 - loss: 0.5589 - acc: 0.724 - ETA: 4:48 - loss: 0.5581 - acc: 0.724 - ETA: 4:42 - loss: 0.5576 - acc: 0.725 - ETA: 4:35 - loss: 0.5587 - acc: 0.724 - ETA: 4:29 - loss: 0.5588 - acc: 0.724 - ETA: 4:22 - loss: 0.5605 - acc: 0.722 - ETA: 4:16 - loss: 0.5592 - acc: 0.724 - ETA: 4:10 - loss: 0.5589 - acc: 0.724 - ETA: 4:04 - loss: 0.5590 - acc: 0.725 - ETA: 3:57 - loss: 0.5594 - acc: 0.725 - ETA: 3:51 - loss: 0.5588 - acc: 0.725 - ETA: 3:44 - loss: 0.5583 - acc: 0.725 - ETA: 3:38 - loss: 0.5584 - acc: 0.725 - ETA: 3:31 - loss: 0.5586 - acc: 0.725 - ETA: 3:25 - loss: 0.5572 - acc: 0.726 - ETA: 3:18 - loss: 0.5572 - acc: 0.726 - ETA: 3:11 - loss: 0.5568 - acc: 0.727 - ETA: 3:04 - loss: 0.5570 - acc: 0.727 - ETA: 2:57 - loss: 0.5570 - acc: 0.727 - ETA: 2:51 - loss: 0.5574 - acc: 0.727 - ETA: 2:44 - loss: 0.5593 - acc: 0.726 - ETA: 2:37 - loss: 0.5578 - acc: 0.727 - ETA: 2:30 - loss: 0.5577 - acc: 0.726 - ETA: 2:23 - loss: 0.5572 - acc: 0.726 - ETA: 2:16 - loss: 0.5559 - acc: 0.727 - ETA: 2:09 - loss: 0.5558 - acc: 0.728 - ETA: 2:03 - loss: 0.5558 - acc: 0.727 - ETA: 1:56 - loss: 0.5554 - acc: 0.727 - ETA: 1:49 - loss: 0.5545 - acc: 0.728 - ETA: 1:42 - loss: 0.5536 - acc: 0.728 - ETA: 1:35 - loss: 0.5535 - acc: 0.729 - ETA: 1:28 - loss: 0.5534 - acc: 0.728 - ETA: 1:22 - loss: 0.5544 - acc: 0.728 - ETA: 1:15 - loss: 0.5542 - acc: 0.728 - ETA: 1:08 - loss: 0.5540 - acc: 0.728 - ETA: 1:01 - loss: 0.5552 - acc: 0.727 - ETA: 54s - loss: 0.5553 - acc: 0.727 - ETA: 47s - loss: 0.5551 - acc: 0.72 - ETA: 41s - loss: 0.5565 - acc: 0.72 - ETA: 34s - loss: 0.5567 - acc: 0.72 - ETA: 27s - loss: 0.5567 - acc: 0.72 - ETA: 20s - loss: 0.5561 - acc: 0.72 - ETA: 13s - loss: 0.5556 - acc: 0.72 - ETA: 6s - loss: 0.5556 - acc: 0.7263 - 919s 230ms/step - loss: 0.5555 - acc: 0.7265 - val_loss: 0.5396 - val_acc: 0.7420\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - ETA: 14:35 - loss: 0.5056 - acc: 0.81 - ETA: 14:17 - loss: 0.5067 - acc: 0.81 - ETA: 14:05 - loss: 0.4767 - acc: 0.83 - ETA: 13:47 - loss: 0.4596 - acc: 0.84 - ETA: 13:33 - loss: 0.4958 - acc: 0.81 - ETA: 13:21 - loss: 0.5085 - acc: 0.79 - ETA: 13:26 - loss: 0.5042 - acc: 0.79 - ETA: 13:41 - loss: 0.5169 - acc: 0.78 - ETA: 13:41 - loss: 0.5087 - acc: 0.78 - ETA: 13:34 - loss: 0.5233 - acc: 0.77 - ETA: 13:20 - loss: 0.5198 - acc: 0.77 - ETA: 13:12 - loss: 0.5205 - acc: 0.78 - ETA: 13:05 - loss: 0.5205 - acc: 0.78 - ETA: 12:58 - loss: 0.5165 - acc: 0.78 - ETA: 12:48 - loss: 0.5113 - acc: 0.78 - ETA: 12:38 - loss: 0.5113 - acc: 0.78 - ETA: 12:28 - loss: 0.5111 - acc: 0.78 - ETA: 12:19 - loss: 0.5106 - acc: 0.78 - ETA: 12:13 - loss: 0.5080 - acc: 0.78 - ETA: 12:18 - loss: 0.5073 - acc: 0.78 - ETA: 12:13 - loss: 0.5025 - acc: 0.78 - ETA: 12:03 - loss: 0.5109 - acc: 0.77 - ETA: 11:54 - loss: 0.5096 - acc: 0.77 - ETA: 11:45 - loss: 0.5057 - acc: 0.78 - ETA: 11:35 - loss: 0.5030 - acc: 0.78 - ETA: 11:27 - loss: 0.5010 - acc: 0.78 - ETA: 11:18 - loss: 0.5008 - acc: 0.78 - ETA: 11:10 - loss: 0.4999 - acc: 0.77 - ETA: 11:01 - loss: 0.5045 - acc: 0.77 - ETA: 10:53 - loss: 0.5052 - acc: 0.77 - ETA: 10:47 - loss: 0.5021 - acc: 0.77 - ETA: 10:40 - loss: 0.5048 - acc: 0.77 - ETA: 10:32 - loss: 0.5015 - acc: 0.77 - ETA: 10:25 - loss: 0.5000 - acc: 0.77 - ETA: 10:18 - loss: 0.4975 - acc: 0.77 - ETA: 10:10 - loss: 0.4996 - acc: 0.77 - ETA: 10:03 - loss: 0.4957 - acc: 0.77 - ETA: 9:58 - loss: 0.4981 - acc: 0.7780 - ETA: 9:52 - loss: 0.4960 - acc: 0.778 - ETA: 9:45 - loss: 0.4968 - acc: 0.778 - ETA: 9:38 - loss: 0.4981 - acc: 0.777 - ETA: 9:30 - loss: 0.4933 - acc: 0.780 - ETA: 9:23 - loss: 0.4927 - acc: 0.780 - ETA: 9:15 - loss: 0.4914 - acc: 0.781 - ETA: 9:08 - loss: 0.4935 - acc: 0.779 - ETA: 9:00 - loss: 0.4919 - acc: 0.778 - ETA: 8:53 - loss: 0.4901 - acc: 0.780 - ETA: 8:45 - loss: 0.4894 - acc: 0.779 - ETA: 8:38 - loss: 0.4909 - acc: 0.776 - ETA: 8:31 - loss: 0.4923 - acc: 0.775 - ETA: 8:23 - loss: 0.4934 - acc: 0.773 - ETA: 8:16 - loss: 0.4914 - acc: 0.776 - ETA: 8:09 - loss: 0.4889 - acc: 0.778 - ETA: 8:02 - loss: 0.4869 - acc: 0.780 - ETA: 7:54 - loss: 0.4860 - acc: 0.781 - ETA: 7:47 - loss: 0.4843 - acc: 0.781 - ETA: 7:40 - loss: 0.4831 - acc: 0.781 - ETA: 7:33 - loss: 0.4838 - acc: 0.781 - ETA: 7:26 - loss: 0.4861 - acc: 0.780 - ETA: 7:19 - loss: 0.4846 - acc: 0.781 - ETA: 7:12 - loss: 0.4838 - acc: 0.782 - ETA: 7:05 - loss: 0.4854 - acc: 0.783 - ETA: 6:58 - loss: 0.4858 - acc: 0.783 - ETA: 6:51 - loss: 0.4878 - acc: 0.781 - ETA: 6:44 - loss: 0.4892 - acc: 0.781 - ETA: 6:37 - loss: 0.4892 - acc: 0.781 - ETA: 6:30 - loss: 0.4903 - acc: 0.780 - ETA: 6:23 - loss: 0.4894 - acc: 0.781 - ETA: 6:16 - loss: 0.4918 - acc: 0.779 - ETA: 6:10 - loss: 0.4919 - acc: 0.780 - ETA: 6:03 - loss: 0.4918 - acc: 0.780 - ETA: 5:56 - loss: 0.4925 - acc: 0.781 - ETA: 5:49 - loss: 0.4915 - acc: 0.782 - ETA: 5:42 - loss: 0.4915 - acc: 0.781 - ETA: 5:35 - loss: 0.4908 - acc: 0.780 - ETA: 5:28 - loss: 0.4933 - acc: 0.779 - ETA: 5:21 - loss: 0.4935 - acc: 0.780 - ETA: 5:15 - loss: 0.4947 - acc: 0.780 - ETA: 5:08 - loss: 0.4940 - acc: 0.780 - ETA: 5:01 - loss: 0.4945 - acc: 0.779 - ETA: 4:54 - loss: 0.4955 - acc: 0.779 - ETA: 4:47 - loss: 0.4946 - acc: 0.780 - ETA: 4:40 - loss: 0.4952 - acc: 0.780 - ETA: 4:34 - loss: 0.4961 - acc: 0.779 - ETA: 4:27 - loss: 0.4969 - acc: 0.777 - ETA: 4:20 - loss: 0.4973 - acc: 0.777 - ETA: 4:14 - loss: 0.4964 - acc: 0.778 - ETA: 4:07 - loss: 0.4964 - acc: 0.777 - ETA: 4:00 - loss: 0.4957 - acc: 0.777 - ETA: 3:54 - loss: 0.4949 - acc: 0.778 - ETA: 3:47 - loss: 0.4967 - acc: 0.777 - ETA: 3:41 - loss: 0.4970 - acc: 0.776 - ETA: 3:34 - loss: 0.4959 - acc: 0.777 - ETA: 3:28 - loss: 0.4961 - acc: 0.776 - ETA: 3:21 - loss: 0.4976 - acc: 0.776 - ETA: 3:14 - loss: 0.4966 - acc: 0.777 - ETA: 3:08 - loss: 0.4962 - acc: 0.777 - ETA: 3:01 - loss: 0.4952 - acc: 0.777 - ETA: 2:54 - loss: 0.4947 - acc: 0.777 - ETA: 2:47 - loss: 0.4949 - acc: 0.776 - ETA: 2:41 - loss: 0.4965 - acc: 0.776 - ETA: 2:35 - loss: 0.4970 - acc: 0.775 - ETA: 2:28 - loss: 0.4972 - acc: 0.775 - ETA: 2:21 - loss: 0.4983 - acc: 0.775 - ETA: 2:15 - loss: 0.4989 - acc: 0.775 - ETA: 2:08 - loss: 0.4993 - acc: 0.774 - ETA: 2:01 - loss: 0.4992 - acc: 0.774 - ETA: 1:54 - loss: 0.4993 - acc: 0.773 - ETA: 1:48 - loss: 0.4982 - acc: 0.774 - ETA: 1:41 - loss: 0.4987 - acc: 0.773 - ETA: 1:34 - loss: 0.4979 - acc: 0.774 - ETA: 1:27 - loss: 0.4975 - acc: 0.774 - ETA: 1:21 - loss: 0.4980 - acc: 0.774 - ETA: 1:14 - loss: 0.4989 - acc: 0.774 - ETA: 1:07 - loss: 0.5005 - acc: 0.773 - ETA: 1:00 - loss: 0.5003 - acc: 0.773 - ETA: 54s - loss: 0.5007 - acc: 0.772 - ETA: 47s - loss: 0.5007 - acc: 0.77 - ETA: 40s - loss: 0.5004 - acc: 0.77 - ETA: 33s - loss: 0.5017 - acc: 0.77 - ETA: 27s - loss: 0.5004 - acc: 0.77 - ETA: 20s - loss: 0.5004 - acc: 0.77 - ETA: 13s - loss: 0.5000 - acc: 0.77 - ETA: 6s - loss: 0.5004 - acc: 0.7729 - 907s 227ms/step - loss: 0.5006 - acc: 0.7730 - val_loss: 0.5456 - val_acc: 0.7280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a31107fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the above result is a little congested, here is a summary.\n",
    "\n",
    "<strong>Epoch 1</strong>\n",
    "<br>Runtime: 1091s\n",
    "Starting Loss/Accuracy: 1.0854  /  50%\n",
    "Ending Loss/Accuracy:   0.5640  /  71.30%\n",
    "\n",
    "<strong>Epoch 2</strong>\n",
    "<br>Runtime: 919s\n",
    "Starting Loss/Accuracy: 0.5390  /  75%\n",
    "Ending Loss/Accuracy:   0.5555  /  74.20%\n",
    "\n",
    "<strong>Epoch 3</strong>\n",
    "<br>Runtime: 907s\n",
    "Starting Loss/Accuracy: 0.5067  /  81%\n",
    "Ending Loss/Accuracy:   0.5456  /  72.80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our Algorithm\n",
    "\n",
    "Since our dataset is so large and we are only utilizing 5000 images from the front, I picked 10 random from near the end of the folder to use as test data.\n",
    "\n",
    "##### Reading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of the images in the test directory\n",
    "testing_images = []\n",
    "testing_images = os.listdir(\"test\")\n",
    "\n",
    "testing_temp = testing_images\n",
    "testing_IDs = []\n",
    "\n",
    "#creating a list of the image IDs to look up real values later\n",
    "for i in range(0, len(testing_temp)):\n",
    "    testing_IDs.append(testing_temp[i].replace(\".jpg\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_load = []\n",
    "\n",
    "for i in range(0,len(testing_images)):\n",
    "    img = image.load_img(\"test/\"+testing_images[i], target_size=(224,224,3), grayscale = False)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    to_load.append(img)\n",
    "    \n",
    "test = np.array(to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions!\n",
    "\n",
    "Remember, 1 corresponds to elliptical, and 2 and 3 correspond to spirals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 2 2 1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes(test)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 3, 3, 1, 1, 1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "val_arr = []\n",
    "\n",
    "\n",
    "for i in range (0, len(testing_IDs)): \n",
    "    for j in range(0, len(rows)):\n",
    "         if rows[j][0] == testing_IDs[i]:\n",
    "                if rows[j][1] > rows[j][2]:\n",
    "                    val_arr.append(1)\n",
    "                else:\n",
    "                    if rows[j][4] > rows[j][5]:\n",
    "                        val_arr.append(2)\n",
    "                    else:\n",
    "                        val_arr.append(3)\n",
    "                \n",
    "print(val_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
